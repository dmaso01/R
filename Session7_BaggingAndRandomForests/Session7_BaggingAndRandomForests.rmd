---
output: html_document
---
<style>
html {
  font-family: Georgia;
  font-size: inherit;
}
body {
  font-family: inherit;
  font-size: inherit;
  font-variant-numeric: lining-nums;
}
h1 {
  font-size: 2rem;
  margin-bottom: 1rem;
}
span.slide {
  font-family: inherit;
  font-size: inherit;
  font-weight: bold;
  background-color: #562435;
  color: white;
  padding: 0.5rem;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, collapse=TRUE, prompt=FALSE, comment=NA, fig.align="center")
```

<h1>Bagging for Regression Trees</h1>

<span class="slide">Slide 11</span> - Apply bagging to the Boston data using the randomForest package in R
```{r}
library(randomForest)
library(MASS)
set.seed(1)
train = sample(1:nrow(Boston), nrow(Boston)/2)
set.seed(6)
bag.boston = randomForest(medv~., data=Boston, subset=train, mtry=13, importance=TRUE)
bag.boston
```

<span class="slide">Slide 12</span> - How well does this bagged model perform on the test set?
```{r}
yhat.bag = predict(bag.boston, newdata=Boston[-train, ])
boston.test = Boston[-train, "medv"]
plot(yhat.bag, boston.test)
abline(0, 1)
mean((yhat.bag - boston.test)^2)
set.seed(6)
bag.boston = randomForest(medv ~ ., data=Boston, subset=train, mtry=13, ntree=25, importance=TRUE)
yhat.bag = predict(bag.boston, newdata=Boston[-train, ])
mean((yhat.bag-boston.test)^2)
```

<span class="slide">Slides 13 & 14</span> - A comparison of Error Rates for Boston Housing Data
```{r}
set.seed(1)
train = sample(1:nrow(Boston), nrow(Boston)*0.5)
train.df = Boston[train,]
test.df = Boston[-train,]
x_train = train.df[-14]
x_test = test.df[-14]
y_train = train.df$medv
y_test = test.df$medv
myForest1 = randomForest(x=x_train, y=y_train, xtest=x_test, ytest=y_test, ntree=100, mtry=13)
plot(1:100, myForest1$test$mse, main="Test Error from Random Forests on the Boston dataset", xlab="Number of Trees", ylab="Test MSE", type= "l", ylim=c(12,22), lwd=1)
abline(h=myForest1$test$mse[1], lty=2, col="red")
```

<h1>Bagging for Classification Trees</h1>

<span class="slide">Slide 17</span> - Apply bagging to the Carseats data using the randomForest package in R
```{r}
library(ISLR)
library(randomForest)
High = ifelse(Carseats$Sales <= 8, "No", "Yes")
Carseats = data.frame(Carseats, High)
set.seed(2)
train = sample(1:nrow(Carseats), nrow(Carseats)/2)
Carseats.test = Carseats[-train,]
High.test = Carseats[-train, "High"]
bag.carseats = randomForest(High ~ .-Sales, data=Carseats, subset=train, mtry=10)
yhat.carseats= predict(bag.carseats, newdata=Carseats.test)
table(yhat.carseats, High.test)
```

<span class="slide">Slides 20-31</span> - Code to obtain the plot[s] on [Slides 20, 24, 28 & 31]
```{r}
library(ISLR)
library(randomForest)
data(Carseats)
High = ifelse(Carseats$Sales <= 8, "No", "Yes")
Carseats.mv = data.frame(Carseats, High)
Carseats.mv = Carseats.mv[, -1]
set.seed(2)
train = sample(400, 200)

#CALCULATE AND PLOT THE BLACK LINE
Carseats.mv.test = Carseats.mv[-train, ]
High.mv.test = Carseats.mv[-train, 11]
test.error.mv = rep(0, 300)
for (i in 1:300) {
  set.seed(4)
  bag.carseats = randomForest(High ~ ., Carseats.mv, subset=train, mtry=10, ntree=i)
  yhat.carseats= predict(bag.carseats, newdata=Carseats.mv.test)
  test.error.mv[i] = (table(yhat.carseats, High.mv.test)[1, 2] + table(yhat.carseats, High.mv.test)[2, 1])/200
}
plot(test.error.mv, 
  xlab="Number of Bootstrap Data Sets", 
  ylab="Test Error Rate", 
  type="l", 
  ylim=c(0.10, 0.35)
)

#PLOT THE RED LINE (Test Error Rate for 1 Decision Tree)
abline(h=test.error.mv[1], lty=2, col="red")

#CALCULATE AND PLOT THE BLUE LINE
Carseats.test = Carseats[-train, -1]
High.ave.test = High.mv.test
test.error.ave = rep(0, 300)
for (j in 1:300) {
  set.seed(2)
  bag.carseats.ave = randomForest(Sales ~ ., Carseats, subset=train, mtry=10, ntree=j)
  yhat.carseats = predict(bag.carseats.ave, newdata=Carseats.test)
  yhat.carseats.class = ifelse(yhat.carseats <= 8, "No", "Yes")
  test.error.ave[j] = (table(yhat.carseats.class, High.ave.test)[1, 2] + table(yhat.carseats.class, High.ave.test)[2, 1])/200
}
lines(test.error.ave, col="blue")

#IMPROVED CODE - ORANGE LINE
data("Carseats")
High = ifelse(Carseats$Sales <= 8, "No", "Yes")
set.seed(2)
train = sample(1:nrow(Carseats), nrow(Carseats)/2)
Carseats = data.frame(Carseats, High)
x_train = Carseats[train, -c(1, 12)]
y_train = Carseats[train, "High"]
x_test = Carseats[-train, -c(1, 12)]
y_test = Carseats[-train, "High"]
set.seed(2)
bag.carseats = randomForest(x=x_train, y=y_train, xtest=x_test, ytest=y_test, ntree=300, mtry=10)
length(bag.carseats$test$err.rate[ , 1])
lines(bag.carseats$test$err.rate[,1], col="orange")

#REGRESSION TREE - GREEN LINE
x_train.ave = Carseats[train, -c(1, 12)]
y_train.ave = Carseats[train, "Sales"]
x_test.ave = Carseats[-train, -c(1, 12)]
y_test.ave = Carseats[-train, "Sales"]
test.error.ave.imp = rep(0, 300)
for (i in 1:300) {
  set.seed(2)
  bag.carseats = randomForest(x=x_train.ave, y=y_train.ave, xtest=x_test.ave, ytest=y_test.ave, ntree=i, mtry=10)
  yhat.High.ave = ifelse(bag.carseats$test$predicted <= 8, "No", "Yes")
  test.error.ave.imp[i] = mean(yhat.High.ave != y_test)
}
lines(test.error.ave.imp, col="green")

#LEGEND
legend("topright", 
  legend = c("single tree", "majority vote", "taking average", "majority vote improved", "taking average improved"), 
  col=c("red", "black", "blue", "orange", "green"), 
  lty=c(2, 1, 1, 1, 1)
)
```

<span class="slide">Slide 34</span> - Out-Of-Bag (OOB) Error Estimation
```{r echo=FALSE}
set.seed(2)
bag.carseats = randomForest(High ~ ., data=Carseats, subset=train, mtry=10)
```
```{r prompt=TRUE}
bag.carseats
```

<span class="slide">Slide 39</span> - Relative Influence Plot (Boston Housing Data)
```{r echo=FALSE}
set.seed(1)
train = sample(1:nrow(Boston), nrow(Boston)/2)
set.seed(6)
bag.boston = randomForest(medv~., data=Boston, subset=train, mtry=13, importance=TRUE)
```
```{r prompt=TRUE}
importance(bag.boston)
```

<span class="slide">Slide 44</span> - Random Forest
```{r}
set.seed(1)
train = sample(nrow(Boston), nrow(Boston)/2)
set.seed(5)
rf.boston = randomForest(medv ~ ., data=Boston, subset=train, mtry=6, importance=TRUE)
yhat.rf = predict(rf.boston, newdata=Boston[-train, ])
boston.test = Boston[-train, "medv"]
mean((yhat.rf - boston.test)^2)
```

<span class="slide">Slide 45</span> - Find the best value of mtry:
```{r}
testMSE = rep(0, 13)
for (i in 1:13) {
  set.seed(5)
  rf.boston = randomForest(medv ~ ., data=Boston, subset=train, mtry=i, importance=TRUE)
  yhat.rf = predict(rf.boston, newdata=Boston[-train, ])
  testMSE[i] = mean((yhat.rf - boston.test)^2)
}
plot(testMSE, type="b", xlab="mtry", ylab="Test MSE")
```

<span class="slide">Slides 51 & 52</span> - A Comparison on Different 'mtry':
```{r}
set.seed(1)
train = sample(1:nrow(Boston), nrow(Boston)*0.5)
train.df = Boston[train, ]
test.df = Boston[-train, ]
x_train = train.df[-14]
x_test = test.df[-14]
y_train = train.df$medv
y_test = test.df$medv
p = ncol(x_train)
myForest1 = randomForest(x=x_train, y=y_train, xtest=x_test, ytest=y_test, ntree=500, mtry=p)
myForest2 = randomForest(x=x_train, y=y_train, xtest=x_test, ytest=y_test, ntree=500, mtry=p/2)
myForest3 = randomForest(x=x_train, y=y_train, xtest=x_test, ytest=y_test, ntree=500, mtry=sqrt(p))
plot(1:500, myForest1$test$mse, 
  main="Test Error from Random Forests on the Boston Dataset",
  xlab="Number of Trees",
  ylab="Test MSE",
  type="l",
  ylim=c(10,20),
  lwd=2,
  las=1, 
  bty="n"
)
lines(1:500, myForest2$test$mse, col="blue", lwd=2)
lines(1:500, myForest3$test$mse, col="orange", lwd=2)
legend("topright",
  c("m = p", "m = p/2", "m = sqrt(p)"),
  col = c("black", "blue", "orange"),
  cex=1,
  lty=1,
  lwd=2,
  bty="n"
)
mtext("Dependent variable: median value of owner-occupied homes 'medv'")
```